challenge_data_engineer/
â”œâ”€â”€ main.py                     # Script principal que orquestra o pipeline
â”œâ”€â”€ src/                        # MÃ³dulos de processamento
â”‚   â”œâ”€â”€ __init__.py             # Torna 'src' um pacote Python
â”‚   â”œâ”€â”€ ingestion_receitafederal.py  # Baixa e extrai os arquivos da Receita Federal
â”‚   â”œâ”€â”€ raw_loader.py           # LÃª os arquivos extraÃ­dos e salva como Delta (camada Raw)
â”‚   â”œâ”€â”€ silver_transformer.py   # Aplica transformaÃ§Ãµes e salva como Delta (camada Silver)
â”‚   â”œâ”€â”€ gold_builder.py         # Une tabelas e gera campos derivados (camada Gold)
â”‚   â”œâ”€â”€ database.py             # Carrega a tabela Gold no banco PostgreSQL
â”œâ”€â”€ data/                       # DiretÃ³rio de dados
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ zip/                # Arquivos ZIP originais
â”‚   â”‚   â””â”€â”€ extraction/         # Arquivos CSV extraÃ­dos
â”‚   â”œâ”€â”€ silver/                 # Dados transformados (Silver)
â”‚   â””â”€â”€ gold/                   # Dados finais (Gold)
â”œâ”€â”€ jars/                       # Driver JDBC do PostgreSQL (.jar)
â”‚   â””â”€â”€ postgresql-42.7.1.jar
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ Dockerfile                  # Define o ambiente do Spark
â””â”€â”€ docker-compose.yml          # Orquestra os serviÃ§os Spark e PostgreSQL

âš™ï¸ Etapas do Pipeline
1. ingestion_receitafederal.py
- Realiza o download dos arquivos da Receita Federal.
- Extrai os arquivos ZIP para data/raw/extraction.
2. raw_loader.py
- LÃª os arquivos CSV extraÃ­dos.
- Aplica os esquemas definidos para SOCIOS e EMPRESAS.
- Salva os dados como tabelas Delta em data/raw.
3. silver_transformer.py
- LÃª os dados da camada Raw.
- Aplica transformaÃ§Ãµes e renomeia colunas.
- Salva os dados como tabelas Delta em data/silver.
4. gold_builder.py
- Une as tabelas EMPRESAS e SOCIOS.
- Cria os campos derivados:
- qtde_socios
- flag_socio_estrangeiro
- doc_alvo
- Salva a tabela final em data/gold.
5. database.py
- LÃª a tabela Gold.
- Conecta ao PostgreSQL via JDBC.
- Salva os dados na tabela empresas_socios_gold.

ğŸš€ Como Executar
1. Instale o driver JDBC
- Baixe o arquivo .jar do site jdbc.postgresql.org
- Coloque em jars/postgresql-42.7.1.jar
2. Construa e execute com Docker Compose
docker-compose up --build


3. Acompanhe os logs
- O pipeline serÃ¡ executado automaticamente via main.py
- A tabela final serÃ¡ carregada no banco desafio_db no PostgreSQL

ğŸ§ª Teste e VisualizaÃ§Ã£o
- Acesse o PostgreSQL via pgAdmin ou DBeaver:
- Host: localhost
- Porta: 5432
- UsuÃ¡rio: admin
- Senha: admin123
- Banco: desafio_db

ğŸ“Œ Requisitos
- Docker e Docker Compose instalados
- Python 3.9+
- Spark com suporte a Delta Lake
- PostgreSQL JDBC Driver (.jar)
